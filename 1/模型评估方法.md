# 模型评估方法

### 混淆矩阵
| 真实值/预测值          正例              反例              |      |      |
| ---------------------------------------------------------- | ---- | ---- |
| 正例                               TP                   FN |      |      |
| 反例                               FP                   TN |      |      |

### acc：准确度是所有预测中预测正确的比例

$$
Acc=\frac{TP+TN}{TP+FN+FP+TN}
$$

### precision：查准率指在所有检测出的目标中检测正确的概率
$$
P=\frac{TP}{TP+FP}
$$

### recall：查全率是指所有的正样本中正确识别的概率。
$$
R=\frac{TP}{TP+FN}
$$
查准率和查全率是一对矛盾的度量，一般而言，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低
### F1：
$$
F1=\frac{2PR}{P+R}
$$

### PRC：
以查准率为Y轴，查全率为X轴做的图。它是综合评价整体结果的评估指标
### BEP：
“查准率=查全率”时的取值，值越大表明分类器性能越好
### ROC：
“受试者工作特征”（Receiver Operating Characteristic）曲线，ROC曲线以“真正例率”（TPR）（查全率吧)为Y轴，以“假正例率”（FPR）(所有确实为“假”的样本中，被误判真的样本）为X轴，对角线对应于“随机猜测”模型，而（0,1）则对应“理想模型”。
$$
TPR=\frac{TP}{TP+FN}
$$

$$
FPR=\frac{FP}{TN+FP}
$$

 AUC（Area Under Curve）的值为ROC曲线下面的面积

### macro-P宏查准率:

$$
macroP=\frac{1}{n}\sum {P_i}
$$
### macro-R宏查全率：

$$
macroP=\frac{1}{n}\sum {R_i}
$$
### macro-F1:

$$
macroP=\frac{2*macroP*macroR}{macroP+macroR}
$$

### micro-P微查准率：

$$
microP=\frac{\overline{TP}}{\overline{TP}+\overline{FP}}
$$
### micro-R微查全率：
$$
microP=\frac{\overline{TP}}{\overline{TP}+\overline{FN}}
$$

