{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import collections\n",
    "from math import log\n",
    "import numpy as np\n",
    "import pandas\n",
    "import graphviz\n",
    "def split_train_test(data,test_ratio):\n",
    "    \"\"\"\n",
    "    分测试集和训练集\n",
    "    \n",
    "    可能会在后剪枝中用到测试集？？\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    randomlist = np.random.permutation(len(data))\n",
    "    test_set_size = round(int(len(data)) * test_ratio)#测试集的大小\n",
    "    test=data[:test_set_size,:]\n",
    "    train= data[test_set_size:,:]\n",
    "    return test,train\n",
    "\n",
    "data = pandas.read_csv('diabetes.csv')\n",
    "data = data.values\n",
    "test,rows = split_train_test(data,0.2)#rows是训练集\n",
    "# print(test)\n",
    "print(type(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    def __init__(self,index=None,value=None,left=None,right=None,result=None):\n",
    "        self.index = index       # 一个数字  列索引值\n",
    "        self.value = value   # 分隔值\n",
    "        self.left = left     # 左子树\n",
    "        self.right = right   # 右子树\n",
    "        self.result = result # 0或1\n",
    "        \n",
    "        \n",
    "def major_class(rows):\n",
    "    \"\"\"\n",
    "    返回最多样本所在的类\n",
    "    Parameters:\n",
    "    -----------\n",
    "    rows:数据集\n",
    "    \n",
    "    Returns:\n",
    "    -------    \n",
    "    result:分类值：0或1\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for row in rows:\n",
    "        value = row[-1]\n",
    "        if value not in results:\n",
    "            results[value] = 0\n",
    "        results[value] += 1\n",
    "    if results[1]>=results[0]:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result\n",
    "\n",
    "def entropy(rows):\n",
    "    \"\"\"\n",
    "    计算信息熵\n",
    "    Parameters:\n",
    "    -----------\n",
    "    rows:数据集\n",
    "    \n",
    "    Returns:\n",
    "    -------    \n",
    "    entropy:信息熵\n",
    "    \"\"\"\n",
    "    m = len(rows)\n",
    "    results = major_class(rows)\n",
    "    entropy = 0\n",
    "    for value in results:\n",
    "        p = float(results[value])/m\n",
    "        entropy -= p*log(p,2)\n",
    "    return entropy\n",
    "    \n",
    "    \n",
    "def Gini(rows):\n",
    "    \"\"\"\n",
    "    计算基尼系数\n",
    "    Parameters:\n",
    "    -----------\n",
    "    rows:数据集\n",
    "    \n",
    "    Returns:\n",
    "    -------    \n",
    "    Gini\n",
    "    \"\"\"\n",
    "    m=len(rows)\n",
    "    labelcount = {}\n",
    "    Gini = 1\n",
    "    for row in rows:\n",
    "        currentlabel = row[-1]\n",
    "        if currentlabel not in labelcount.keys():\n",
    "            labelcount[currentlabel] = 0\n",
    "        labelcount[currentlabel]+=1\n",
    "    for value in labelcount:\n",
    "        Gini -= (value/m)**2\n",
    "    return Gini      \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class CART(DecisionTree):\n",
    "    pass\n",
    "\n",
    "def split_data(rows,index,split):\n",
    "    \"\"\"\n",
    "    rows:数据集\n",
    "    index:列索引值\n",
    "    split:在CART算法中是对应的最好分隔值\n",
    "    \"\"\"\n",
    "    left = [row for row in rows if row[index] >= split]\n",
    "    right = [row for row in rows if row[index] < split]\n",
    "    return (left,right)\n",
    "    \n",
    "    \n",
    "def buildTree(rows):\n",
    "    \"\"\"\n",
    "    递归构建决策树\n",
    "    \"\"\"\n",
    "    if len(rows) == 0:\n",
    "        return DecisionTree()\n",
    "    bestGain = 0\n",
    "    #i是列数\n",
    "    for index in range(0,len(rows[0])-1):# 应该  要减去1因为不要最好一列？？\n",
    "        values = [row[index] for row in rows]\n",
    "        for value in values:\n",
    "            (set1,set2) = split_data(rows,i,j)\n",
    "            p = float(len(set1))/len(rows)\n",
    "            gain = Gini(rows) - p*Gini(set1) - (1-p)*Gini(set2)\n",
    "            if gain>bestGain and len(set1)>0 and len(set2)>0:\n",
    "                bestGain = gain\n",
    "                best_index = index\n",
    "                best_value = value\n",
    "    if bestGain > 0:\n",
    "        left = buildTree(bestSets[0]) # set1\n",
    "        right = buildTree(bestSets[1]) # set2\n",
    "        return DecisionTree(index=best_index,\n",
    "                        value=best_value,left=left,right=right)\n",
    "    else:\n",
    "        return DecisionTree(results=major_class(rows))\n",
    "        \n",
    "        \n",
    "def pre_prune(DecisionTree,minGain):\n",
    "    \"\"\"\n",
    "    预剪枝\n",
    "    \"\"\"\n",
    "    lb,rb = [],[]\n",
    "    #遍历之后大概是一堆1和0\n",
    "    for v,c in DecisionTree.left.results.items():\n",
    "        lb += [[v]] *c\n",
    " \n",
    "    for v,c in DecisionTree.right.results.items():\n",
    "        rb += [[v]] *c\n",
    "    m = len(lb+rb)\n",
    "    p = float(len(lb))/m\n",
    "    prune_Gain = Gini(lb+tb) - p*Gini(lb) - (1-p)*Gini(rb)\n",
    "    #如果增益小于某一个设定的值，就进行剪枝\n",
    "    if prune_Gain < minGain:\n",
    "        tree.left,tree.right = None\n",
    "        tree.results = major_class(rb+lb)\n",
    "\n",
    "            \n",
    "def predict(test,tree):\n",
    "    \"\"\"\n",
    "    计算在测试集上的错误率\n",
    "    \"\"\"\n",
    "    m = len(test)\n",
    "    n = 0\n",
    "    for row in test:\n",
    "        prediction = classify(row)\n",
    "        if prediction == row[-1]:\n",
    "            n+=1\n",
    "    ratio = (m-n)/m\n",
    "    return ratio\n",
    "            \n",
    "\n",
    "def REP_prune(DecisionTree,test):\n",
    "    \"\"\"\n",
    "    似乎不怎么正确的后剪枝\n",
    "    \"\"\"\n",
    "    current_ratio = (test,DecisionTree)\n",
    "    if DecisionTree.left.results != None and DecisionTree.right.results !=None:\n",
    "        DecisionTree.left,DecisionTree.right = None\n",
    "        DecisionTree.results = major_class(rb+lb)\n",
    "        ratio = predict(test,DecisionTree)\n",
    "        if ratio <current_ratio:#剪枝后的错误率变小??\n",
    "            return REP_prune(DecisionTree,test)\n",
    "        else:\n",
    "            DecisionTree = buildTree(rows)\n",
    "            \n",
    "\n",
    "    \n",
    "def classify(rows,DecisionTree):\n",
    "    \"\"\"\n",
    "    进行分类\n",
    "    \"\"\"\n",
    "    if DecisionTree.result !=None:\n",
    "        return DecisionTree.results\n",
    "    else:\n",
    "        value = rows[tree.col]\n",
    "        branch = None\n",
    "        if value >= DecisionTree.value:\n",
    "            branch = DecisionTree.left\n",
    "        else:\n",
    "            branch = DecisionTree.right\n",
    "    return classify(rows,branch)\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-35-cec671bdcc89>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-35-cec671bdcc89>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class ID3(DecisionTree):\n",
    "    pass\n",
    "\n",
    "    def split_data(rows,index,split):\n",
    "        \"\"\"\n",
    "        rows:数据集\n",
    "        index:列索引值\n",
    "        split:在ID3算法中是对应的特征值\n",
    "        \"\"\"\n",
    "        left = [row for row in rows if row[index] == split]\n",
    "        right = [row for row in rows if row[index] !=split]\n",
    "        return (left,right)\n",
    "    \n",
    "\n",
    "     \n",
    "    \n",
    "    def buildTree(rows):\n",
    "    \"\"\"\n",
    "    递归构建决策树\n",
    "    \"\"\"\n",
    "    if len(rows) == 0:\n",
    "        return DecisionTree()\n",
    "    bestGain = 0\n",
    "    #i是列数\n",
    "    for index in range(0,len(rows[0])-1):# 应该  要减去1因为不要最好一列？？\n",
    "        values = [row[index] for row in rows]\n",
    "        for value in values:\n",
    "            (set1,set2) = split_data(rows,i,j)\n",
    "            p = float(len(set1))/len(rows)\n",
    "            gain = entropy(rows) - p*entropy(set1) - (1-p)*entropy(set2)\n",
    "            if gain>bestGain and len(set1)>0 and len(set2)>0:\n",
    "                bestGain = gain\n",
    "                best_index = index\n",
    "                best_value = value\n",
    "    if bestGain > 0:\n",
    "        left = buildTree(bestSets[0]) # set1\n",
    "        right = buildTree(bestSets[1]) # set2\n",
    "        return DecisionTree(index=best_index,\n",
    "                        value=best_value,left=left,right=right)\n",
    "    else:\n",
    "        return DecisionTree(results=major_class(rows))\n",
    "    \n",
    "    \n",
    "    def classify(rows,DecisionTree):\n",
    "        \"\"\"\n",
    "        进行分类\n",
    "        \"\"\"\n",
    "        if DecisionTree.result !=None:\n",
    "            return DecisionTree.results\n",
    "        else:\n",
    "            value = rows[tree.col]\n",
    "            branch = None\n",
    "            if value == DecisionTree.value:\n",
    "                branch = DecisionTree.left\n",
    "            else:\n",
    "                branch = DecisionTree.right\n",
    "        return classify(rows,branch)\n",
    "    \n",
    "\n",
    "class C45(DecisionTree):\n",
    "    pass\n",
    "\n",
    "    def split_data(rows,index,split):\n",
    "        \"\"\"\n",
    "        rows:数据集\n",
    "        index:列索引值\n",
    "        split:在C45算法中是对应的特征值\n",
    "        \"\"\"\n",
    "        left = [row for row in rows if row[index] == split]\n",
    "        right = [row for row in rows if row[index] !=split]\n",
    "        return (left,right)\n",
    "\n",
    "\n",
    "\n",
    "    def buildTree(rows):\n",
    "    \"\"\"\n",
    "    递归构建决策树\n",
    "    \"\"\"\n",
    "    if len(rows) == 0:\n",
    "        return DecisionTree()\n",
    "    bestGain = 0\n",
    "    #i是列数\n",
    "    for index in range(0,len(rows[0])-1):# 应该  要减去1因为不要最后一列？？\n",
    "        values = [row[index] for row in rows]\n",
    "        for value in values:\n",
    "            (set1,set2) = split_data(rows,i,j)\n",
    "            p = float(len(set1))/len(rows)\n",
    "            gain = (entropy(rows) - p*entropy(set1) - (1-p)*entropy(set2))/entropy(rows)\n",
    "            if gain>bestGain and len(set1)>0 and len(set2)>0:\n",
    "                bestGain = gain\n",
    "                best_index = index\n",
    "                best_value = value\n",
    "    if bestGain > 0:\n",
    "        left = buildTree(bestSets[0]) # set1\n",
    "        right = buildTree(bestSets[1]) # set2\n",
    "        return DecisionTree(index=best_index,\n",
    "                        value=best_value,left=left,right=right)\n",
    "    else:\n",
    "        return DecisionTree(results=major_class(rows))\n",
    "    \n",
    "    \n",
    "    def classify(rows,DecisionTree):\n",
    "        \"\"\"\n",
    "        进行分类\n",
    "        \"\"\"\n",
    "        if DecisionTree.result !=None:\n",
    "            return DecisionTree.results\n",
    "        else:\n",
    "            value = rows[tree.col]\n",
    "            branch = None\n",
    "            if value == DecisionTree.value:\n",
    "                branch = DecisionTree.left\n",
    "            else:\n",
    "                branch = DecisionTree.right\n",
    "        return classify(rows,branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-d0d9fc186bae>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-34-d0d9fc186bae>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    if DecisionTree.left\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tree = buildTree(rows)\n",
    "\n",
    "# 失败的可视化  还没有学懂graphviz\n",
    "\n",
    "from graphviz import Digraph\n",
    "dot = Digraph(comment='tree')\n",
    "dot.node('o', ' ')\n",
    "def view(DecisionTree):\n",
    "    dot.node('o','feature%s>=%s' %(DecisionTree.col,DecisionTree.value))\n",
    "    dot.node('L','feature%s>=%s' %(DecisionTree.col,DecisionTree.value))\n",
    "    dot.node('R','feature%s<%s' %(DecisionTree.col,DecisionTree.value))\n",
    "\n",
    "    dot.edges('o','L',Y)\n",
    "    if DecisionTree.right != None:\n",
    "        return view(DecisionTree.right)    \n",
    "    dot.edges('o','R',N)\n",
    "    if DecisionTree.right != None:\n",
    "        return view(DecisionTree.right)\n",
    "view(DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[6.000e+00, 1.370e+02, 6.100e+01, ..., 1.510e-01, 5.500e+01,\n",
      "        0.000e+00],\n",
      "       [0.000e+00, 1.790e+02, 9.000e+01, ..., 6.860e-01, 2.300e+01,\n",
      "        1.000e+00],\n",
      "       [3.000e+00, 8.300e+01, 5.800e+01, ..., 3.360e-01, 2.500e+01,\n",
      "        0.000e+00],\n",
      "       ...,\n",
      "       [2.000e+00, 1.230e+02, 4.800e+01, ..., 5.200e-01, 2.600e+01,\n",
      "        0.000e+00],\n",
      "       [3.000e+00, 1.730e+02, 8.200e+01, ..., 2.137e+00, 2.500e+01,\n",
      "        1.000e+00],\n",
      "       [4.000e+00, 1.270e+02, 8.800e+01, ..., 5.980e-01, 2.800e+01,\n",
      "        0.000e+00]]), array([[  7.   , 142.   ,  60.   , ...,   0.687,  61.   ,   0.   ],\n",
      "       [  1.   , 172.   ,  68.   , ...,   0.702,  28.   ,   1.   ],\n",
      "       [  4.   , 132.   ,   0.   , ...,   0.302,  23.   ,   1.   ],\n",
      "       ...,\n",
      "       [  3.   , 142.   ,  80.   , ...,   0.2  ,  63.   ,   0.   ],\n",
      "       [  1.   , 121.   ,  78.   , ...,   0.261,  28.   ,   0.   ],\n",
      "       [  2.   ,  94.   ,  76.   , ...,   0.649,  23.   ,   0.   ]]), array([[1.00e+01, 7.50e+01, 8.20e+01, ..., 2.63e-01, 3.80e+01, 0.00e+00],\n",
      "       [0.00e+00, 1.29e+02, 8.00e+01, ..., 7.03e-01, 2.90e+01, 0.00e+00],\n",
      "       [2.00e+00, 9.90e+01, 5.20e+01, ..., 6.37e-01, 2.10e+01, 0.00e+00],\n",
      "       ...,\n",
      "       [0.00e+00, 1.19e+02, 0.00e+00, ..., 1.41e-01, 2.40e+01, 1.00e+00],\n",
      "       [0.00e+00, 1.02e+02, 5.20e+01, ..., 7.80e-02, 2.10e+01, 0.00e+00],\n",
      "       [0.00e+00, 1.19e+02, 6.60e+01, ..., 2.59e-01, 2.20e+01, 0.00e+00]]), array([[6.00e+00, 9.10e+01, 0.00e+00, ..., 5.01e-01, 3.10e+01, 0.00e+00],\n",
      "       [1.10e+01, 1.03e+02, 6.80e+01, ..., 1.26e-01, 4.20e+01, 0.00e+00],\n",
      "       [9.00e+00, 7.20e+01, 7.80e+01, ..., 2.80e-01, 3.80e+01, 0.00e+00],\n",
      "       ...,\n",
      "       [4.00e+00, 1.73e+02, 7.00e+01, ..., 3.61e-01, 3.30e+01, 1.00e+00],\n",
      "       [1.00e+00, 9.10e+01, 6.40e+01, ..., 1.92e-01, 2.10e+01, 0.00e+00],\n",
      "       [0.00e+00, 1.47e+02, 8.50e+01, ..., 3.75e-01, 2.40e+01, 0.00e+00]]), array([[9.00e+00, 8.90e+01, 6.20e+01, ..., 1.42e-01, 3.30e+01, 0.00e+00],\n",
      "       [1.00e+00, 8.30e+01, 6.80e+01, ..., 6.24e-01, 2.70e+01, 0.00e+00],\n",
      "       [7.00e+00, 1.95e+02, 7.00e+01, ..., 1.63e-01, 5.50e+01, 1.00e+00],\n",
      "       ...,\n",
      "       [4.00e+00, 1.34e+02, 7.20e+01, ..., 2.77e-01, 6.00e+01, 1.00e+00],\n",
      "       [1.00e+00, 9.70e+01, 6.40e+01, ..., 2.99e-01, 2.10e+01, 0.00e+00],\n",
      "       [0.00e+00, 1.31e+02, 6.60e+01, ..., 1.96e-01, 2.20e+01, 1.00e+00]]), array([[  6.   , 114.   ,   0.   , ...,   0.189,  26.   ,   0.   ],\n",
      "       [  0.   , 162.   ,  76.   , ...,   0.364,  26.   ,   1.   ],\n",
      "       [  9.   ,  72.   ,  78.   , ...,   0.28 ,  38.   ,   0.   ],\n",
      "       ...,\n",
      "       [  8.   , 126.   ,  74.   , ...,   0.162,  39.   ,   0.   ],\n",
      "       [  2.   , 155.   ,  52.   , ...,   0.24 ,  25.   ,   1.   ],\n",
      "       [  0.   , 104.   ,  76.   , ...,   0.582,  27.   ,   0.   ]]), array([[  9.   , 112.   ,  82.   , ...,   1.282,  50.   ,   1.   ],\n",
      "       [  7.   , 119.   ,   0.   , ...,   0.209,  37.   ,   0.   ],\n",
      "       [ 12.   , 140.   ,  85.   , ...,   0.244,  41.   ,   0.   ],\n",
      "       ...,\n",
      "       [  3.   , 174.   ,  58.   , ...,   0.593,  36.   ,   1.   ],\n",
      "       [  3.   , 102.   ,  44.   , ...,   0.4  ,  26.   ,   0.   ],\n",
      "       [  0.   , 119.   ,  64.   , ...,   0.725,  23.   ,   0.   ]]), array([[  3.   , 173.   ,  82.   , ...,   2.137,  25.   ,   1.   ],\n",
      "       [  1.   , 119.   ,  88.   , ...,   0.507,  26.   ,   0.   ],\n",
      "       [  0.   , 180.   ,  90.   , ...,   0.314,  35.   ,   1.   ],\n",
      "       ...,\n",
      "       [  1.   , 125.   ,  50.   , ...,   0.962,  28.   ,   1.   ],\n",
      "       [  8.   , 100.   ,  74.   , ...,   0.661,  43.   ,   1.   ],\n",
      "       [  3.   ,  74.   ,  68.   , ...,   0.293,  23.   ,   0.   ]]), array([[0.00e+00, 9.50e+01, 8.50e+01, ..., 2.47e-01, 2.40e+01, 1.00e+00],\n",
      "       [9.00e+00, 1.34e+02, 7.40e+01, ..., 4.60e-01, 8.10e+01, 0.00e+00],\n",
      "       [5.00e+00, 1.68e+02, 6.40e+01, ..., 1.35e-01, 4.10e+01, 1.00e+00],\n",
      "       ...,\n",
      "       [3.00e+00, 9.90e+01, 6.20e+01, ..., 2.79e-01, 2.60e+01, 0.00e+00],\n",
      "       [3.00e+00, 1.11e+02, 6.20e+01, ..., 1.42e-01, 2.10e+01, 0.00e+00],\n",
      "       [3.00e+00, 1.06e+02, 7.20e+01, ..., 2.07e-01, 2.70e+01, 0.00e+00]]), array([[1.000e+00, 1.090e+02, 5.600e+01, ..., 8.330e-01, 2.300e+01,\n",
      "        0.000e+00],\n",
      "       [3.000e+00, 1.250e+02, 5.800e+01, ..., 1.510e-01, 2.400e+01,\n",
      "        0.000e+00],\n",
      "       [9.000e+00, 5.700e+01, 8.000e+01, ..., 9.600e-02, 4.100e+01,\n",
      "        0.000e+00],\n",
      "       ...,\n",
      "       [7.000e+00, 1.960e+02, 9.000e+01, ..., 4.510e-01, 4.100e+01,\n",
      "        1.000e+00],\n",
      "       [1.000e+00, 1.160e+02, 7.000e+01, ..., 2.040e-01, 2.100e+01,\n",
      "        0.000e+00],\n",
      "       [1.000e+00, 1.280e+02, 8.800e+01, ..., 1.057e+00, 3.700e+01,\n",
      "        1.000e+00]])]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'DecisionTree' has no attribute 'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8d4c24010806>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mclass_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDecisionTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mclass_0\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-2e36a06fbf6b>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(rows, DecisionTree)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[0m进行分类\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \"\"\"\n\u001b[1;32m--> 177\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[1;33m!=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'DecisionTree' has no attribute 'result'"
     ]
    }
   ],
   "source": [
    "#尝试实现随机森林\n",
    "\n",
    "data = pandas.read_csv('diabetes.csv')\n",
    "data = data.values\n",
    "def randomTrees(n,rows):\n",
    "    \"\"\"\n",
    "    用有放回的方式 随机生成n组数据\n",
    "    \n",
    "    rows:数据集\n",
    "    randomTrees：n组数据\n",
    "    \"\"\"\n",
    "    np.random.shuffle(rows)#打乱数据\n",
    "    randomTrees = []\n",
    "    h = rows.shape[0]\n",
    "    for i in range(n):\n",
    "        index = np.random.choice(h,h,replace=True)#重排列\n",
    "        randomTree = rows[index,:]\n",
    "        randomTrees.append(randomTree)\n",
    "    return randomTrees\n",
    "a=randomTrees(10,data)\n",
    "print(a)\n",
    "\n",
    "\n",
    "#进行投票\n",
    "class_0 = 0\n",
    "class_1 = 1\n",
    "for i in range(len(a)-1):\n",
    "    result = classify(a[i],DecisionTree)\n",
    "    if result == 0:\n",
    "        class_0 += 1\n",
    "    else:\n",
    "        class_1 +=1\n",
    "\n",
    "if class_0 >= class_1:\n",
    "    random_forest_result = 0\n",
    "else:\n",
    "    random_forest_result = 1\n",
    "    \n",
    "#我发现我随机选择了特征之后就把这个特征是啥给搞没了  所以暂时还是不用随机选择特征了  这个随机森林是一个只有随机选择数据的随机森林     \n",
    "# def randomFeatures(rows):\n",
    "#     \"\"\"\n",
    "#     随机选取特征\n",
    "#     rows:数据集\n",
    "    \n",
    "    \n",
    "#     \"\"\"\n",
    "    \n",
    "#     n=rows.shape[1]#特征的数量\n",
    "#     subset = randomTrees(n,rows)\n",
    "#     m=len(subset)\n",
    "#     max_feature=int(np.sqrt(n))#一颗树选取的最大特征 选择给n开方\n",
    "#     index = np.random.choice(n,max_feature)\n",
    "#     subset=subset[i]\n",
    "#     subset_x=np.array(subset)[:,index]\n",
    "#     subset_y=subset[:,-1,np.newaxis]\n",
    "        \n",
    "#     subset=np.hstack((subset_x,subset_y))\n",
    "#     return subset\n",
    "\n",
    "# trees = []\n",
    "# for i in range(len(a)-1):\n",
    "#     subset = a[i]\n",
    "#     subset = randomFeatures(subset)\n",
    "#     trees.append(subset)\n",
    "\n",
    "# print(trees)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-17-200afdd3eb93>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-200afdd3eb93>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    dot = Digraph(comment='The Round Table')\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[[   213]\n",
      " [  4324]\n",
      " [ 45353]\n",
      " [456456]\n",
      " [456456]\n",
      " [    45]\n",
      " [     6]]\n",
      "[[1.00000e+00 2.13000e+02]\n",
      " [2.00000e+00 4.32400e+03]\n",
      " [3.00000e+00 4.53530e+04]\n",
      " [4.00000e+00 4.56456e+05]\n",
      " [5.00000e+00 4.56456e+05]\n",
      " [6.00000e+00 4.50000e+01]\n",
      " [7.80000e+00 6.00000e+00]]\n",
      "[[2.00000e+00 4.32400e+03]\n",
      " [3.00000e+00 4.53530e+04]\n",
      " [4.00000e+00 4.56456e+05]\n",
      " [1.00000e+00 2.13000e+02]\n",
      " [7.80000e+00 6.00000e+00]\n",
      " [5.00000e+00 4.56456e+05]\n",
      " [6.00000e+00 4.50000e+01]]\n"
     ]
    }
   ],
   "source": [
    "#一些无关的测试\n",
    "\n",
    "x=np.array([1,2,3,4,5,6,7.8])\n",
    "m=x.shape[0]\n",
    "print(m)\n",
    "x=x.reshape(7,1)\n",
    "y=np.array([213,4324,45353,456456,456456,45,6])\n",
    "y = y.reshape(m,1)\n",
    "print(y)\n",
    "x_y = np.hstack((x,y))\n",
    "\n",
    "print(x_y)\n",
    "np.random.shuffle(x_y)\n",
    "print(x_y)\n",
    "dataset=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 0]\n",
      "[[435 324 243]\n",
      " [ 11 321 342]\n",
      " [ 11 321 342]]\n"
     ]
    }
   ],
   "source": [
    "x_y=np.array([[11,321,342],\n",
    "            [23,42,423],\n",
    "            [435,324,243]])\n",
    "\n",
    "m=3\n",
    "index = np.random.choice(m,m,replace=True)\n",
    "print(index)\n",
    "bootstrap_x_y = x_y[index,:]\n",
    "print(bootstrap_x_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
