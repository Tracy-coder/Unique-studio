{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import collections\n",
    "from math import log\n",
    "import numpy as np\n",
    "import pandas\n",
    "import graphviz\n",
    "def split_train_test(data,test_ratio):\n",
    "    \"\"\"\n",
    "    分测试集和训练集\n",
    "    \n",
    "    可能会在后剪枝中用到测试集？？\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    randomlist = np.random.permutation(len(data))\n",
    "    test_set_size = round(int(len(data)) * test_ratio)#测试集的大小\n",
    "    test=data[:test_set_size,:]\n",
    "    train= data[test_set_size:,:]\n",
    "    return test,train\n",
    "\n",
    "data = pandas.read_csv('diabetes.csv')\n",
    "data = data.values\n",
    "test,rows = split_train_test(data,0.2)#rows是训练集\n",
    "# print(test)\n",
    "print(type(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    def __init__(self,index=None,value=None,left=None,right=None,results=None,result=None):\n",
    "        self.index = index       # 一个数字  列索引值\n",
    "        self.value = value   # 分隔值\n",
    "        self.left = left     # 左子树\n",
    "        self.right = right   # 右子树\n",
    "        self.results = results # 0或1\n",
    "        self.result = result\n",
    "        \n",
    "        \n",
    "def major_class(rows):\n",
    "    \"\"\"\n",
    "    返回最多样本所在的类\n",
    "    Parameters:\n",
    "    -----------\n",
    "    rows:数据集\n",
    "    \n",
    "    Returns:\n",
    "    -------    \n",
    "    result:分类值：0或1\n",
    "    \"\"\"\n",
    "    results = [0,0]\n",
    "    for row in rows:\n",
    "        value = row[-1]\n",
    "        if value==0:\n",
    "            results[0]+=1\n",
    "        else:\n",
    "            results[1]+=1\n",
    "    if results[1]>=results[0]:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result,results\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def Gini(rows):\n",
    "    \"\"\"\n",
    "    计算基尼系数\n",
    "    Parameters:\n",
    "    -----------\n",
    "    rows:数据集\n",
    "    \n",
    "    Returns:\n",
    "    -------    \n",
    "    Gini\n",
    "    \"\"\"\n",
    "    m=len(rows)\n",
    "    labelcount = {}\n",
    "    Gini = 1\n",
    "    for row in rows:\n",
    "        currentlabel = row[-1]\n",
    "        if currentlabel not in labelcount.keys():\n",
    "            labelcount[currentlabel] = 0\n",
    "        labelcount[currentlabel]+=1\n",
    "    for value in labelcount:\n",
    "        Gini -= (value/m)**2\n",
    "    return Gini      \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class CART(DecisionTree):\n",
    "    pass\n",
    "\n",
    "def split_data(rows,index,split):\n",
    "    \"\"\"\n",
    "    rows:数据集\n",
    "    index:列索引值\n",
    "    split:在CART算法中是对应的最好分隔值\n",
    "    \"\"\"\n",
    "    left = [row for row in rows if row[index] >= split]\n",
    "    right = [row for row in rows if row[index] < split]\n",
    "    return (left,right)\n",
    "    \n",
    "    \n",
    "def buildTree(rows):\n",
    "    \"\"\"\n",
    "    递归构建决策树\n",
    "    \"\"\"\n",
    "    if len(rows) == 0:\n",
    "        return DecisionTree()\n",
    "    bestGain = 0\n",
    "    #i是列数\n",
    "    for index in range(0,len(rows[0])-1):# 应该  要减去1因为不要最后一列？？\n",
    "        values = [row[index] for row in rows]\n",
    "        for value in values:\n",
    "            (set1,set2) = split_data(rows,index,value)\n",
    "            p = float(len(set1))/len(rows)\n",
    "            gain = Gini(rows) - p*Gini(set1) - (1-p)*Gini(set2)\n",
    "            if gain>bestGain and len(set1)>0 and len(set2)>0:\n",
    "                bestGain = gain\n",
    "                best_index = index\n",
    "                best_value = value\n",
    "    if bestGain > 0:\n",
    "        left = buildTree(set1) \n",
    "        right = buildTree(set2) \n",
    "        return DecisionTree(index=best_index,\n",
    "                        value=best_value,left=left,right=right)\n",
    "    else:\n",
    "        return DecisionTree(results=major_class(rows))\n",
    "        \n",
    "        \n",
    "# def pre_prune(DecisionTree,minGain):\n",
    "#     \"\"\"\n",
    "#     预剪枝\n",
    "#     \"\"\"\n",
    "#     lb,rb = [],[]\n",
    "#     #遍历之后大概是一堆1和0\n",
    "#     for v,c in DecisionTree.left.results.items():\n",
    "#         lb += [[v]] *c\n",
    " \n",
    "#     for v,c in DecisionTree.right.results.items():\n",
    "#         rb += [[v]] *c\n",
    "#     m = len(lb+rb)\n",
    "#     p = float(len(lb))/m\n",
    "#     prune_Gain = Gini(lb+tb) - p*Gini(lb) - (1-p)*Gini(rb)\n",
    "#     #如果增益小于某一个设定的值，就进行剪枝\n",
    "#     if prune_Gain < minGain:\n",
    "#         tree.left,tree.right = None\n",
    "#         tree.results = major_class(rb+lb)\n",
    "\n",
    "            \n",
    "# def predict(test,tree):\n",
    "#     \"\"\"\n",
    "#     计算在测试集上的错误率\n",
    "#     \"\"\"\n",
    "#     m = len(test)\n",
    "#     n = 0\n",
    "#     for row in test:\n",
    "#         prediction = classify(row)\n",
    "#         if prediction == row[-1]:\n",
    "#             n+=1\n",
    "#     ratio = (m-n)/m\n",
    "#     return ratio\n",
    "            \n",
    "\n",
    "# def REP_prune(DecisionTree,test):\n",
    "#     \"\"\"\n",
    "#     似乎不怎么正确的后剪枝\n",
    "#     \"\"\"\n",
    "#     current_ratio = (test,DecisionTree)\n",
    "#     if DecisionTree.left.results != None and DecisionTree.right.results !=None:\n",
    "#         DecisionTree.left,DecisionTree.right = None\n",
    "#         DecisionTree.results = major_class(rb+lb)\n",
    "#         ratio = predict(test,DecisionTree)\n",
    "#         if ratio <current_ratio:#剪枝后的错误率变小??\n",
    "#             return REP_prune(DecisionTree,test)\n",
    "#         else:\n",
    "#             DecisionTree = buildTree(rows)\n",
    "            \n",
    "\n",
    "    \n",
    "def classify(rows,DecisionTree):\n",
    "    \"\"\"\n",
    "    进行分类\n",
    "    \"\"\"\n",
    "    if DecisionTree.result !=None:\n",
    "        return DecisionTree.results\n",
    "    else:\n",
    "        value = rows[tree.col]\n",
    "        branch = None\n",
    "        if value >= DecisionTree.value:\n",
    "            branch = DecisionTree.left\n",
    "        else:\n",
    "            branch = DecisionTree.right\n",
    "    return classify(rows,branch)\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = buildTree(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ID3(DecisionTree):\n",
    "    pass\n",
    "\n",
    "\n",
    "def entropy(rows):\n",
    "    m = len(rows)\n",
    "    results = major_class(rows)\n",
    "    entropy = 0.0\n",
    "    p1 = float(len(results[0])/len(m))\n",
    "    p2 = float(len(results[1])/len(m))\n",
    "    entropy = -p1*log(p1,2)-p2*log(p2,2)\n",
    "    return entropy\n",
    "\n",
    "    def split_data(rows,index,split):\n",
    "        \"\"\"\n",
    "        rows:数据集\n",
    "        index:列索引值\n",
    "        split:在ID3算法中是对应的特征值\n",
    "        \"\"\"\n",
    "        left = [row for row in rows if row[index] == split]\n",
    "        right = [row for row in rows if row[index] !=split]\n",
    "        return (left,right)\n",
    "    \n",
    "\n",
    "     \n",
    "    \n",
    "def buildTree(rows):\n",
    "    \"\"\"\n",
    "    递归构建决策树\n",
    "    \"\"\"\n",
    "    if len(rows) == 0:\n",
    "        return DecisionTree()\n",
    "    bestGain = 0\n",
    "    #i是列数\n",
    "    for index in range(0,len(rows[0])-1):# 应该  要减去1因为不要最好一列？？\n",
    "        values = [row[index] for row in rows]\n",
    "        for value in values:\n",
    "            (set1,set2) = split_data(rows,i,j)\n",
    "            p = float(len(set1))/len(rows)\n",
    "            gain = entropy(rows) - p*entropy(set1) - (1-p)*entropy(set2)\n",
    "            if gain>bestGain and len(set1)>0 and len(set2)>0:\n",
    "                bestGain = gain\n",
    "                best_index = index\n",
    "                best_value = value\n",
    "    if bestGain > 0:\n",
    "        left = buildTree(bestSets[0]) # set1\n",
    "        right = buildTree(bestSets[1]) # set2\n",
    "        return DecisionTree(index=best_index,\n",
    "                        value=best_value,left=left,right=right)\n",
    "    else:\n",
    "        return DecisionTree(results=major_class(rows))\n",
    "    \n",
    "    \n",
    "    def classify(rows,DecisionTree):\n",
    "        \"\"\"\n",
    "        进行分类\n",
    "        \"\"\"\n",
    "        if DecisionTree.result !=None:\n",
    "            return DecisionTree.results\n",
    "        else:\n",
    "            value = rows[tree.col]\n",
    "            branch = None\n",
    "            if value == DecisionTree.value:\n",
    "                branch = DecisionTree.left\n",
    "            else:\n",
    "                branch = DecisionTree.right\n",
    "        return classify(rows,branch)\n",
    "    \n",
    "\n",
    "class C45(DecisionTree):\n",
    "    pass\n",
    "\n",
    "    def split_data(rows,index,split):\n",
    "        \"\"\"\n",
    "        rows:数据集\n",
    "        index:列索引值\n",
    "        split:在C45算法中是对应的特征值\n",
    "        \"\"\"\n",
    "        left = [row for row in rows if row[index] == split]\n",
    "        right = [row for row in rows if row[index] !=split]\n",
    "        return (left,right)\n",
    "\n",
    "\n",
    "\n",
    "def buildTree(rows):\n",
    "    \"\"\"\n",
    "    递归构建决策树\n",
    "    \"\"\"\n",
    "    if len(rows) == 0:\n",
    "        return DecisionTree()\n",
    "    bestGain = 0\n",
    "    #i是列数\n",
    "    for index in range(0,len(rows[0])-1):# 应该  要减去1因为不要最后一列？？\n",
    "        values = [row[index] for row in rows]\n",
    "        for value in values:\n",
    "            (set1,set2) = split_data(rows,index,value)\n",
    "            p = float(len(set1))/len(rows)\n",
    "            gain = (entropy(rows) - p*entropy(set1) - (1-p)*entropy(set2))/entropy(rows)\n",
    "            if gain>bestGain and len(set1)>0 and len(set2)>0:\n",
    "                bestGain = gain\n",
    "                best_index = index\n",
    "                best_value = value\n",
    "    if bestGain > 0:\n",
    "        left = buildTree(bestSets[0]) # set1\n",
    "        right = buildTree(bestSets[1]) # set2\n",
    "        return DecisionTree(index=best_index,\n",
    "                        value=best_value,left=left,right=right)\n",
    "    else:\n",
    "        return DecisionTree(results=major_class(rows))\n",
    "    \n",
    "    \n",
    "    def classify(rows,DecisionTree):\n",
    "        \"\"\"\n",
    "        进行分类\n",
    "        \"\"\"\n",
    "        if DecisionTree.result !=None:\n",
    "            return DecisionTree.results\n",
    "        else:\n",
    "            value = rows[tree.col]\n",
    "            branch = None\n",
    "            if value == DecisionTree.value:\n",
    "                branch = DecisionTree.left\n",
    "            else:\n",
    "                branch = DecisionTree.right\n",
    "        return classify(rows,branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 失败的可视化  还完全没有学懂graphviz\n",
    "\n",
    "from graphviz import Digraph\n",
    "dot = Digraph(comment='tree')\n",
    "dot.node('o', ' ')\n",
    "def view(DecisionTree):\n",
    "    dot.node('o','feature%s>=%s' %(DecisionTree.col,DecisionTree.value))\n",
    "    dot.node('L','feature%s>=%s' %(DecisionTree.col,DecisionTree.value))\n",
    "    dot.node('R','feature%s<%s' %(DecisionTree.col,DecisionTree.value))\n",
    "\n",
    "    dot.edges('o','L',Y)\n",
    "    if DecisionTree.right != None:\n",
    "        return view(DecisionTree.right)    \n",
    "    dot.edges('o','R',N)\n",
    "    if DecisionTree.right != None:\n",
    "        return view(DecisionTree.right)\n",
    "view(DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#失败的随机森林\n",
    "\n",
    "data = pandas.read_csv('diabetes.csv')\n",
    "data = data.values\n",
    "def randomTrees(n,rows):\n",
    "    \"\"\"\n",
    "    用有放回的方式 随机生成n组数据\n",
    "    \n",
    "    rows:数据集\n",
    "    randomTrees：n组数据\n",
    "    \"\"\"\n",
    "    np.random.shuffle(rows)#打乱数据\n",
    "    randomTrees = []\n",
    "    h = rows.shape[0]\n",
    "    for i in range(n):\n",
    "        index = np.random.choice(h,h,replace=True)#重排列\n",
    "        randomTree = rows[index,:]\n",
    "        randomTrees.append(randomTree)\n",
    "    return randomTrees\n",
    "a=randomTrees(10,data)\n",
    "print(a)\n",
    "\n",
    "\n",
    "#进行投票\n",
    "class_0 = 0\n",
    "class_1 = 1\n",
    "for i in range(len(a)-1):\n",
    "    result = classify(a[i],DecisionTree)\n",
    "    if result == 0:\n",
    "        class_0 += 1\n",
    "    else:\n",
    "        class_1 +=1\n",
    "\n",
    "if class_0 >= class_1:\n",
    "    random_forest_result = 0\n",
    "else:\n",
    "    random_forest_result = 1\n",
    "    \n",
    "#我发现我随机选择了特征之后就把这个特征是啥给搞没了  所以暂时还是不用随机选择特征了  这个随机森林是一个只有随机选择数据的随机森林     \n",
    "# def randomFeatures(rows):\n",
    "#     \"\"\"\n",
    "#     随机选取特征\n",
    "#     rows:数据集\n",
    "    \n",
    "    \n",
    "#     \"\"\"\n",
    "    \n",
    "#     n=rows.shape[1]#特征的数量\n",
    "#     subset = randomTrees(n,rows)\n",
    "#     m=len(subset)\n",
    "#     max_feature=int(np.sqrt(n))#一颗树选取的最大特征 选择给n开方\n",
    "#     index = np.random.choice(n,max_feature)\n",
    "#     subset=subset[i]\n",
    "#     subset_x=np.array(subset)[:,index]\n",
    "#     subset_y=subset[:,-1,np.newaxis]\n",
    "        \n",
    "#     subset=np.hstack((subset_x,subset_y))\n",
    "#     return subset\n",
    "\n",
    "# trees = []\n",
    "# for i in range(len(a)-1):\n",
    "#     subset = a[i]\n",
    "#     subset = randomFeatures(subset)\n",
    "#     trees.append(subset)\n",
    "\n",
    "# print(trees)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
