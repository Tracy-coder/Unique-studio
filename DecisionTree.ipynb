{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class DecisionTree(object):\n",
    "    def __init__(self,impurity,left,right,split,labels,data=[]):\n",
    "        self.split = split  #划分值\n",
    "        self.data = data[1:,:]   #数据集\n",
    "        self.impurity = impurity  #纯度 有三种指标\n",
    "        self.right = right  #左子树\n",
    "        self.left = left   #右子树\n",
    "        self.labels = data[0,:]\n",
    "        \n",
    "    def chooseBest(self,data):\n",
    "        \"\"\"\n",
    "        选择最好的划分值\n",
    "        data:数据集\n",
    "        return：最好的划分值，特征所在的列\n",
    "        \"\"\"\n",
    "    \n",
    "        sorted_data = np.sort(data[:, :-1], axis=0)#不要最后一行 进行整理 axis=0表示按列排序\n",
    "        sorted_data = sorted_data.T.tolist()#转置，且将数组转换为列表 相当于列表嵌套 写到一行了\n",
    "\n",
    "        for row in range(len(sorted_data)):#row取了一行 因为是转置过的矩阵 所以其实是原来的一列\n",
    "            sorted_ = sorted_data[row]#按照数字大小进行的整理 应该\n",
    "            sorted_set = sorted(list(set(sorted_)))#对于数字去重 再整理  得到一个嵌套列表\n",
    "\n",
    "            split = [(sorted_set[i] + sorted_set[i + 1]) / 2 for i in range(len(sorted_set)-2)]#依次计算了平均值  构成了一个比原来小的列表\n",
    "            for value in split:#对于这个平均值列表里的每一个平均值 进行分裂左右节点  node_实际上是一个数字\n",
    "                left = data[np.where(data[:, row] <= value)[0], :]\n",
    "                right = data[np.where(data[:, row] > value)[0], :]\n",
    "                impurity = calculate(left,right,data)#计算在该种分裂方式下 纯度（信息增益 增益率或者基尼系数）\n",
    "                if impurity >= max_impurity:\n",
    "                    best_split = split\n",
    "                    axis = row\n",
    "            # print(self.method + ' max value: ' + str(max_impurity))\n",
    "            # print(combine_df[combine_df[index_] <= best_node].groupby(combine_df['label'])['label'].count())\n",
    "            # print(combine_df[combine_df[index_] > best_node].groupby(combine_df['label'])['label'].count())\n",
    "        return best_split,axis\n",
    "        \n",
    "    \n",
    "    def entropy(dataset):\n",
    "        \"\"\"   \n",
    "        计算信息熵\n",
    "        \"\"\"\n",
    "        m = len(dataset)\n",
    "        labelcount = {}\n",
    "        for data in dataset:\n",
    "            currentlabel = data[-1]\n",
    "            if currentlabel not in labelcount.keys():\n",
    "                labelcount[currentlabel] = 0\n",
    "            labelcount[currentlabel]+=1\n",
    "        entrop = 0\n",
    "        for label in labelcount:\n",
    "            p = float(labelcount[label])/m\n",
    "            entropy-=log2(p)\n",
    "        return entropy\n",
    "    \n",
    "    \n",
    "    def Gini(dataset):\n",
    "        \"\"\"\n",
    "        计算基尼属性值\n",
    "        \"\"\"\n",
    "      \n",
    "        m=dataset\n",
    "        labelcount = {}\n",
    "        for data in dataset:\n",
    "            currentlabel = data[-1]\n",
    "            if currentlabel not in labelcount.keys():\n",
    "                labelcount[currentlabel] = 0\n",
    "            labelcount[currentlabel]+=1\n",
    "        a = len(labelcount[0])/m\n",
    "        b = len(labelcount[1])/m\n",
    "        Gini = 1-a*a-b*b\n",
    "        return Gini\n",
    "        \n",
    "    \n",
    "    def vote(classlist):\n",
    "        \"\"\"\n",
    "        当特征值为1时，进行投票表决\n",
    "        \"\"\"\n",
    "        classcount={}\n",
    "        for class_ in classlist:\n",
    "            if (class_ not in classcount.keys()):\n",
    "                classcount[class_] = 0\n",
    "            classcount[class_] += 1\n",
    "        if classcount[0] >=classcount[1]:\n",
    "            result=0\n",
    "        else:\n",
    "            result=1\n",
    "        return result\n",
    "            \n",
    "            \n",
    "        \n",
    "    def split_data(dataset,split,axis):\n",
    "        \"\"\"\n",
    "        划分左右子树\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        dataset：数据集\n",
    "        split：划分值\n",
    "        axis：划分的特征所在的列\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        left：左子树\n",
    "        right：右子树\n",
    "        \"\"\"\n",
    "        left=[]\n",
    "        right=[]\n",
    "        for data in dateset:\n",
    "            if(data[axis] < split):\n",
    "                data_x = data[:axis]\n",
    "                data_x.extend(data[axis+1:])\n",
    "                left.append(data_x)\n",
    "            if(data[axis] >= split):\n",
    "                data_x = data[:axis]\n",
    "                data_x.extend(data[axis+1:])\n",
    "                right.append(data_x)\n",
    "        return left,right\n",
    "    \n",
    "    \n",
    "    def buildTree(dataset,labels):\n",
    "        \"\"\"\n",
    "        构建决策树\n",
    "        Parameters：\n",
    "        ------------\n",
    "        dataset:数据集\n",
    "        labels:标签\n",
    "        \n",
    "        Returns：\n",
    "        ---------\n",
    "        decision_tree:一个字典\n",
    "        \n",
    "        \"\"\"\n",
    "        labels = labels\n",
    "        fealabels=[]\n",
    "        classlist=[example[-1] for example in dataset]\n",
    "        if (len(classlist)==classlist.count(classlist[0])):#当前的所有样本均属于同一类\n",
    "            return classlist[0]\n",
    "        if (len(dataset[0])==1):#属性剩余一个\n",
    "            majorclass=vote(classlist)\n",
    "            return majorclass\n",
    "        decision_tree = {best_split:{}}\n",
    "        value,axis = chooseBest(dataset)\n",
    "        left,right = split_data(dataset,value,axis)\n",
    "        return DecisionTree(left=left,right=right)\n",
    "    \n",
    "class ID3(DecisionTree):\n",
    "    def calculate(left,right,dataset):\n",
    "        \"\"\"\n",
    "        计算纯度--信息增益\n",
    "        Parameters：\n",
    "        -------------\n",
    "        dataset：数据集\n",
    "        left：左子树\n",
    "        right：右子树\n",
    "        Returns：\n",
    "        --------\n",
    "        impurity：纯度\n",
    "    \n",
    "        \"\"\"\n",
    "        value,axis = chooseBest(dataset)\n",
    "        left,right = split_data(dataset,axis,value)\n",
    "        origin_ent = entropy(dataset)\n",
    "        p1 = float(len(left)/len(dataset))\n",
    "        p2 = float(len(right)/len(dataset))\n",
    "        info_gain = origin_ent-p1*entropy(left)-p2*entropy(right)\n",
    "        impurity = info_gain\n",
    "        return impurity\n",
    "        \n",
    "        \n",
    "class C45(DecisionTree):\n",
    "    def calculate(left,right,dataset):\n",
    "        \"\"\"\n",
    "        计算纯度--信息增益率\n",
    "        Parameters：\n",
    "        -------------\n",
    "        dataset：数据集\n",
    "        left：左子树\n",
    "        right：右子树\n",
    "        Returns：\n",
    "        --------\n",
    "        impurity：纯度\n",
    "    \n",
    "        \"\"\"\n",
    "        value,axis = chooseBest(dataset)\n",
    "        left,right = split_data(dataset,axis,value)\n",
    "        origin_ent = entropy(dataset)\n",
    "        p1 = float(len(left)/len(dataset))\n",
    "        p2 = float(len(right)/len(dataset))\n",
    "        info_gain = origin_ent-p1*entropy(left)-p2*entropy(right)\n",
    "        impurity=float(info_gain/origin_ent)\n",
    "        return impurity\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class CART(DecisionTree):\n",
    "    def calculate(left,right,dataset):\n",
    "        \"\"\"\n",
    "        计算纯度--基尼增益\n",
    "        Parameters：\n",
    "        -------------\n",
    "        dataset：数据集\n",
    "        left：左子树\n",
    "        right：右子树\n",
    "        Returns：\n",
    "        --------\n",
    "        impurity：纯度\n",
    "    \n",
    "        \"\"\"\n",
    "        value,axis = chooseBest(dataset)\n",
    "        left,right = split_data(dataset,axis,value)\n",
    "        p1 = float(len(left)/len(dataset))\n",
    "        p2 = float(len(right)/len(dataset))\n",
    "        impurity=p1*Gini(left)+p2*Gini(right)\n",
    "        return impurity\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data=tree.export_graphviz(model,\n",
    "                              feature_names=   ,\n",
    "                              class_names= ,)\n",
    "graph=graphviz.Source(dot_data)\n",
    "graph.render('computer')\n",
    "graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
